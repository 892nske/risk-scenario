{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a75b691",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02e17ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNG_SEED = 42\n",
    "np.random.seed(RNG_SEED)\n",
    "random.seed(RNG_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42cfe625",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Scenario:\n",
    "    name: str\n",
    "    equity_index: float   # e.g., -0.10 for -10%\n",
    "    jgb_10y_bps: float    # e.g., +50 for +50 bps\n",
    "    usd_jpy_change: float # e.g., -5.0 means JPY appreciation by 5 yen (USDJPY down 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7372529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mock_data(num_accounts: int = 20, num_instruments: int = 50, as_of_date: str = \"2025-10-27\"):\n",
    "    \"\"\"\n",
    "    Generates mock instruments, accounts, holdings, exposures.\n",
    "    Returns dict of DataFrames.\n",
    "    \"\"\"\n",
    "    # Instruments universe: mix of equity (JPY), bond (JPY), foreign equity (USD)\n",
    "    instrument_ids = [f\"INS{1000+i}\" for i in range(num_instruments)]\n",
    "    types = np.random.choice([\"equity\", \"bond\", \"equity_fx\"], size=num_instruments, p=[0.5, 0.3, 0.2])\n",
    "    currencies = np.where(types==\"equity_fx\", \"USD\", \"JPY\")\n",
    "    names = [f\"{t.upper()}_{i}\" for i,t in zip(instrument_ids, types)]\n",
    "    prices = np.round(np.random.uniform(500, 10000, size=num_instruments), 2)\n",
    "\n",
    "    instruments = pd.DataFrame({\n",
    "        \"instrument_id\": instrument_ids,\n",
    "        \"name\": names,\n",
    "        \"type\": types,\n",
    "        \"currency\": currencies,\n",
    "        \"price\": prices\n",
    "    })\n",
    "\n",
    "    # Factor exposures\n",
    "    # equity: beta ~ N(1.0, 0.3)\n",
    "    # bond: duration Uniform(2,8), convexity Uniform(0.1, 0.6)\n",
    "    betas = np.clip(np.random.normal(1.0, 0.3, size=num_instruments), 0.2, 2.0)\n",
    "    durations = np.random.uniform(2.0, 8.0, size=num_instruments)\n",
    "    convexities = np.random.uniform(0.1, 0.6, size=num_instruments)\n",
    "\n",
    "    exposures = []\n",
    "    for ins_id, t, b, d, c in zip(instrument_ids, types, betas, durations, convexities):\n",
    "        if t in [\"equity\", \"equity_fx\"]:\n",
    "            exposures.append({\"instrument_id\": ins_id, \"factor\": \"equity_beta\", \"value\": float(b)})\n",
    "        if t == \"bond\":\n",
    "            exposures.append({\"instrument_id\": ins_id, \"factor\": \"duration\", \"value\": float(d)})\n",
    "            exposures.append({\"instrument_id\": ins_id, \"factor\": \"convexity\", \"value\": float(c)})\n",
    "    exposures = pd.DataFrame(exposures)\n",
    "\n",
    "    # Accounts\n",
    "    account_ids = [f\"ACC{10000+i}\" for i in range(num_accounts)]\n",
    "    customers = [f\"CUST{200+i}\" for i in range(num_accounts)]\n",
    "    account_currencies = np.random.choice([\"JPY\",\"JPY\",\"JPY\",\"USD\"], size=num_accounts, p=[0.6,0.2,0.1,0.1])  # mostly JPY\n",
    "    accounts = pd.DataFrame({\n",
    "        \"account_id\": account_ids,\n",
    "        \"customer_id\": customers,\n",
    "        \"currency\": account_currencies,\n",
    "        \"status\": [\"active\"]*num_accounts\n",
    "    })\n",
    "\n",
    "    # Holdings: each account holds between 6 and 15 names\n",
    "    rows = []\n",
    "    for acc in account_ids:\n",
    "        n_hold = random.randint(6, 15)\n",
    "        pick_idx = np.random.choice(range(num_instruments), size=n_hold, replace=False)\n",
    "        for idx in pick_idx:\n",
    "            ins = instruments.iloc[idx]\n",
    "            qty = float(np.random.uniform(5, 200))\n",
    "            rows.append({\n",
    "                \"account_id\": acc,\n",
    "                \"instrument_id\": ins[\"instrument_id\"],\n",
    "                \"quantity\": qty,\n",
    "                \"as_of_date\": as_of_date\n",
    "            })\n",
    "    holdings = pd.DataFrame(rows)\n",
    "\n",
    "    # FX snapshot: USDJPY level (for converting USD to JPY and vice versa)\n",
    "    fx_snapshot = {\n",
    "        \"as_of_date\": as_of_date,\n",
    "        \"USDJPY\": 150.0  # base level\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        \"instruments\": instruments,\n",
    "        \"exposures\": exposures,\n",
    "        \"accounts\": accounts,\n",
    "        \"holdings\": holdings,\n",
    "        \"fx\": fx_snapshot\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da3411cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_scenario(data: Dict[str, pd.DataFrame], scenario: Scenario) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Apply shock scenario to all holdings and aggregate to account-level results.\n",
    "    Returns (account_results, holding_results).\n",
    "    \"\"\"\n",
    "    instruments = data[\"instruments\"].copy()\n",
    "    exposures = data[\"exposures\"].copy()\n",
    "    accounts = data[\"accounts\"].copy()\n",
    "    holdings = data[\"holdings\"].copy()\n",
    "    fx = data[\"fx\"]\n",
    "\n",
    "    # Merge holdings with instrument info\n",
    "    h = holdings.merge(instruments, on=\"instrument_id\", how=\"left\")\n",
    "    h = h.merge(exposures.pivot_table(index=\"instrument_id\", columns=\"factor\", values=\"value\", aggfunc=\"first\").reset_index(), on=\"instrument_id\", how=\"left\")\n",
    "\n",
    "    # Base prices and values in local currency\n",
    "    h[\"base_price\"] = h[\"price\"]\n",
    "    h[\"base_value_local\"] = h[\"quantity\"] * h[\"base_price\"]\n",
    "\n",
    "    # Compute local price shock by type\n",
    "    # Equity: dP/P = beta * equity_index\n",
    "    equity_mask = h[\"type\"].isin([\"equity\", \"equity_fx\"])\n",
    "    h.loc[equity_mask, \"dP_over_P_local\"] = h.loc[equity_mask, \"equity_beta\"].fillna(1.0) * scenario.equity_index\n",
    "\n",
    "    # Bond: dP/P = -Dur * dy + 0.5 * Conv * dy^2 (dy in absolute)\n",
    "    bond_mask = h[\"type\"] == \"bond\"\n",
    "    dy = scenario.jgb_10y_bps / 10000.0\n",
    "    h.loc[bond_mask, \"dP_over_P_local\"] = (\n",
    "        - h.loc[bond_mask, \"duration\"].fillna(0.0) * dy\n",
    "        + 0.5 * h.loc[bond_mask, \"convexity\"].fillna(0.0) * (dy ** 2)\n",
    "    )\n",
    "\n",
    "    # Default zero move for others\n",
    "    h[\"dP_over_P_local\"] = h[\"dP_over_P_local\"].fillna(0.0)\n",
    "\n",
    "    # Shocked local price & value\n",
    "    h[\"shocked_price_local\"] = h[\"base_price\"] * (1.0 + h[\"dP_over_P_local\"])\n",
    "    h[\"shocked_value_local\"] = h[\"quantity\"] * h[\"shocked_price_local\"]\n",
    "\n",
    "    # FX conversion to account currency:\n",
    "    USDJPY_base = fx[\"USDJPY\"]\n",
    "    USDJPY_shocked = USDJPY_base + scenario.usd_jpy_change  # e.g., -5 means JPY strengthens (USDJPY down)\n",
    "    USDJPY_shocked = max(USDJPY_shocked, 0.0001)  # guard\n",
    "\n",
    "    def convert_value(row, value_col: str, shocked: bool) -> float:\n",
    "        ins_ccy = row[\"currency\"]\n",
    "        acc_ccy = row[\"account_currency\"]\n",
    "        if ins_ccy == acc_ccy:\n",
    "            return row[value_col]\n",
    "        if ins_ccy == \"USD\" and acc_ccy == \"JPY\":\n",
    "            rate = USDJPY_shocked if shocked else USDJPY_base\n",
    "            return row[value_col] * rate\n",
    "        if ins_ccy == \"JPY\" and acc_ccy == \"USD\":\n",
    "            rate = USDJPY_shocked if shocked else USDJPY_base\n",
    "            return row[value_col] / rate\n",
    "        # Other pairs omitted in PoC\n",
    "        return row[value_col]\n",
    "\n",
    "    # attach account currency\n",
    "    acc_ccy_map = dict(zip(accounts[\"account_id\"], accounts[\"currency\"]))\n",
    "    h[\"account_currency\"] = h[\"account_id\"].map(acc_ccy_map)\n",
    "\n",
    "    # Convert base & shocked values into account currency\n",
    "    h[\"base_value_acc\"] = h.apply(lambda r: convert_value(r, \"base_value_local\", shocked=False), axis=1)\n",
    "    h[\"shocked_value_acc\"] = h.apply(lambda r: convert_value(r, \"shocked_value_local\", shocked=True), axis=1)\n",
    "\n",
    "    # Factor contributions via isolated shocks (equity-only, rate-only, fx-only)\n",
    "    h_eq = h.copy()\n",
    "    h_eq[\"dP_over_P_local_eq\"] = 0.0\n",
    "    h_eq.loc[equity_mask, \"dP_over_P_local_eq\"] = h_eq.loc[equity_mask, \"equity_beta\"].fillna(1.0) * scenario.equity_index\n",
    "    h_eq[\"shocked_value_local_eq\"] = h_eq[\"quantity\"] * h_eq[\"base_price\"] * (1.0 + h_eq[\"dP_over_P_local_eq\"])\n",
    "    h_eq[\"value_acc_eq\"] = h_eq.apply(lambda r: convert_value(r, \"shocked_value_local_eq\", shocked=False), axis=1)  # FX unchanged for pure equity factor\n",
    "\n",
    "    h_rt = h.copy()\n",
    "    h_rt[\"dP_over_P_local_rt\"] = 0.0\n",
    "    h_rt.loc[bond_mask, \"dP_over_P_local_rt\"] = (\n",
    "        - h_rt.loc[bond_mask, \"duration\"].fillna(0.0) * dy\n",
    "        + 0.5 * h_rt.loc[bond_mask, \"convexity\"].fillna(0.0) * (dy ** 2)\n",
    "    )\n",
    "    h_rt[\"shocked_value_local_rt\"] = h_rt[\"quantity\"] * h_rt[\"base_price\"] * (1.0 + h_rt[\"dP_over_P_local_rt\"])\n",
    "    h_rt[\"value_acc_rt\"] = h_rt.apply(lambda r: convert_value(r, \"shocked_value_local_rt\", shocked=False), axis=1)  # FX unchanged for pure rate factor\n",
    "\n",
    "    h_fx = h.copy()\n",
    "    h_fx[\"value_acc_fx\"] = h_fx.apply(lambda r: convert_value(r, \"base_value_local\", shocked=True), axis=1)\n",
    "\n",
    "    # Aggregate to account\n",
    "    grp_cols = [\"account_id\", \"account_currency\"]\n",
    "    base_sum = h.groupby(grp_cols)[\"base_value_acc\"].sum().rename(\"base_value\")\n",
    "    shocked_sum = h.groupby(grp_cols)[\"shocked_value_acc\"].sum().rename(\"shocked_value\")\n",
    "\n",
    "    eq_only = h_eq.groupby(grp_cols)[\"value_acc_eq\"].sum().rename(\"value_eq_only\")\n",
    "    rt_only = h_rt.groupby(grp_cols)[\"value_acc_rt\"].sum().rename(\"value_rt_only\")\n",
    "    fx_only = h_fx.groupby(grp_cols)[\"value_acc_fx\"].sum().rename(\"value_fx_only\")\n",
    "\n",
    "    results = pd.concat([base_sum, shocked_sum, eq_only, rt_only, fx_only], axis=1).reset_index()\n",
    "    results[\"pnl_abs\"] = results[\"shocked_value\"] - results[\"base_value\"]\n",
    "    results[\"pnl_pct\"] = np.where(results[\"base_value\"] != 0, results[\"pnl_abs\"] / results[\"base_value\"], np.nan)\n",
    "\n",
    "    results[\"contrib_eq\"] = results[\"value_eq_only\"] - results[\"base_value\"]\n",
    "    results[\"contrib_rt\"] = results[\"value_rt_only\"] - results[\"base_value\"]\n",
    "    results[\"contrib_fx\"] = results[\"value_fx_only\"] - results[\"base_value\"]\n",
    "\n",
    "    # Scale contributions to match total PnL (handles cross-terms approx.)\n",
    "    contrib_sum = results[[\"contrib_eq\",\"contrib_rt\",\"contrib_fx\"]].sum(axis=1)\n",
    "    mismatch = results[\"pnl_abs\"] - contrib_sum\n",
    "    weight = results[[\"contrib_eq\",\"contrib_rt\",\"contrib_fx\"]].abs().sum(axis=1).replace(0.0, np.nan)\n",
    "    for col in [\"contrib_eq\", \"contrib_rt\", \"contrib_fx\"]:\n",
    "        results[col] = results[col] + (results[col].abs()/weight).fillna(1/3) * mismatch\n",
    "\n",
    "    # Holding-level details\n",
    "    h_detail = h.copy()\n",
    "    h_detail[\"pnl_abs\"] = h_detail[\"shocked_value_acc\"] - h_detail[\"base_value_acc\"]\n",
    "    h_detail[\"pnl_pct\"] = np.where(h_detail[\"base_value_acc\"] != 0, h_detail[\"pnl_abs\"]/h_detail[\"base_value_acc\"], np.nan)\n",
    "\n",
    "    return results, h_detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d34ecdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = generate_mock_data(num_accounts=30, num_instruments=80, as_of_date=\"2025-10-27\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee852563",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario = Scenario(\n",
    "    name=\"Equity -10%, Rates +50bp, JPY +5 (USDJPY -5)\",\n",
    "    equity_index=-0.10,\n",
    "    jgb_10y_bps=50.0,\n",
    "    usd_jpy_change=-5.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57f98f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "account_results, holding_results = apply_scenario(data, scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "176a8a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "accounts = data[\"accounts\"][[\"account_id\",\"customer_id\",\"currency\"]].rename(columns={\"currency\":\"account_currency\"})\n",
    "account_results = account_results.merge(accounts, on=[\"account_id\",\"account_currency\"], how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431b49fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
